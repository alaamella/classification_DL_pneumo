{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CHEST X-RAY Pneumonia Classification with EfficientNet\n",
        "\n",
        "This notebook ports the experiment shared by **nikoneri**. It leverages TensorFlow's EfficientNetB0 backbone with an unfreezing stage for fine-tuning on the chest X-ray dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "DATA_ROOT = Path('..') / 'data' / 'chest_xray'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build `tf.data` datasets\n",
        "\n",
        "Using `image_dataset_from_directory` keeps the pipeline close to the original implementation while providing efficient, batched datasets compatible with mixed precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = image_dataset_from_directory(\n",
        "    DATA_ROOT / 'train',\n",
        "    label_mode='binary',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    DATA_ROOT / 'val',\n",
        "    label_mode='binary',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    DATA_ROOT / 'test',\n",
        "    label_mode='binary',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prefetch and augment\n",
        "\n",
        "Basic augmentation replicates the behavior of the published notebook and improves generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1.0 / 255)\n",
        "\n",
        "data_augmentation = models.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(normalization_layer(x)), y), num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the EfficientNet model\n",
        "\n",
        "We start with a frozen backbone for rapid convergence, then unfreeze the top layers for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=IMG_SIZE + (3,))\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the frozen backbone\n",
        "\n",
        "Training the classifier head establishes a strong initialization before unfreezing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "initial_history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tune the network\n",
        "\n",
        "We unfreeze the last few blocks and continue training with a lower learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate on the test dataset\n",
        "\n",
        "The final accuracy helps compare across different contributor notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = model.evaluate(test_ds)\n",
        "print(dict(zip(model.metrics_names, results)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model weights\n",
        "\n",
        "Persisting the trained weights makes it easy to deploy the classifier elsewhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('nikoneri_efficientnet_pneumonia')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}