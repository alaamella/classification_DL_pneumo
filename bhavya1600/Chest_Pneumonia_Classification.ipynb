{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chest Pneumonia Classification in Keras\n",
        "\n",
        "This notebook mirrors the TensorFlow/Keras workflow authored by **bhavya1600**. It performs exploratory analysis, builds a convolutional neural network, and evaluates the model on the validation and test splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "DATA_ROOT = Path('..') / 'data' / 'chest_xray'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data generators\n",
        "\n",
        "We rely on `ImageDataGenerator` for on-the-fly augmentation and rescaling. The generators are pointed at the `train`, `val`, and `test` directories following the shared repository layout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_ROOT / 'train',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    DATA_ROOT / 'val',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    DATA_ROOT / 'test',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize a batch\n",
        "\n",
        "Having a quick look at the augmented images ensures the orientation and class balance look reasonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, labels = next(train_generator)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title('PNEUMONIA' if labels[i] else 'NORMAL')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the CNN\n",
        "\n",
        "The architecture combines convolutional blocks with batch normalization and dropout to reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=IMG_SIZE + (3,)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the network\n",
        "\n",
        "The callbacks monitor validation performance and reduce the learning rate on plateau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot learning curves\n",
        "\n",
        "A combined plot of accuracy and loss helps benchmark the run against previous experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(history.history['accuracy'], label='train')\n",
        "axes[0].plot(history.history['val_accuracy'], label='val')\n",
        "axes[0].set_title('Accuracy')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history.history['loss'], label='train')\n",
        "axes[1].plot(history.history['val_loss'], label='val')\n",
        "axes[1].set_title('Loss')\n",
        "axes[1].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate on the test split\n",
        "\n",
        "We gather predictions, compute classification metrics, and visualize the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = model.predict(test_generator)\n",
        "pred_labels = (preds.ravel() > 0.5).astype(int)\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "print(classification_report(true_labels, pred_labels, target_names=test_generator.class_indices.keys()))\n",
        "\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(test_generator.class_indices))\n",
        "plt.xticks(tick_marks, test_generator.class_indices.keys(), rotation=45)\n",
        "plt.yticks(tick_marks, test_generator.class_indices.keys())\n",
        "\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
        "\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model\n",
        "\n",
        "Persisting the weights allows the trained network to be re-used or shared without rerunning the entire training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('bhavya1600_pneumonia_classifier.h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}